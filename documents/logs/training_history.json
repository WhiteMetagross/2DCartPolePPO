{
    "reward_history": [
        49.3,
        111.9,
        235.1,
        448.3,
        500.0
    ],
    "eval_rewards": [
        49.3,
        111.9,
        235.1,
        448.3,
        500.0
    ],
    "steps": [
        40960,
        81920
    ],
    "eval_steps": [
        2,
        4,
        6,
        8,
        10
    ],
    "final_reward": 500.0,
    "total_updates": 10,
    "total_timesteps": 81920
}